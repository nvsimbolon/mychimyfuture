{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Class Assignment - Apr 6\n",
    "### Due: April 8, 5pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Import all the libraries and tools you need below. **(0.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# linear regression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Read the **Life_Exp_Data.csv** file. It is a clean (almost) version of World Health Organization statistics on life expectancy. Prepare the dataset for Linear Regression.\n",
    "\n",
    "**a)** Drop the first (Unnamed: 0) column. \n",
    "\n",
    "**b)** The life expectancy should be the target value and the rest should be the features.\n",
    "\n",
    "**c)** Split the dataset into training and test sets with a 80-20 ratio. \n",
    "\n",
    "**d)** Scale the features using either your own implementation or a sklearn object. \n",
    "\n",
    "**(2.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Life_Exp_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Life expectancy ']\n",
    "X = data.drop(['Life expectancy '], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Write the first helper function for the Gradient Descent algorithm. It should be called **initialize** and take one input called **dim**, which is the number of features. It should return two outputs: **weights**, which is a vector of non-zero (random or fixed) numbers and **bias**, which is a scalar, random or fixed. \n",
    "\n",
    "Try your function with a few different numbers to see if it works properly. For the input 18, it should return a 18x1 weight vector and a scalar bias.\n",
    "\n",
    "**(3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def initialize(dim):\n",
    "    weights = vector = np.ones((dim,1))\n",
    "    bias = random.uniform(-1, 1)\n",
    "    d = dict(enumerate(weights.flatten(), 1))\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]),\n",
       " 0.30616383777252043)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** On which part of Gradient Descent will you need the **initialize** function? **(0.5 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use initialize function in the first step of GD, where we initialize the values of weights and bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Write the second helper function which is **predict**. It should take two inputs: (1) **model_parameters** which is a dictionary with the strings **weights** and **bias** as keys and the weight vector and the bias as values. (2) **X_test**, which is the (scaled) test features. It should return **y_pred** which is the predicted target values.\n",
    "\n",
    "Try your function with the weights and bias (do not forget to put them in a dictionary and use the correct dimension) you obtained from the **initialize** function above and the test features to see if it works properly.\n",
    "\n",
    "**(3.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_parameters, X_test):\n",
    "    keys = ['weights','bias']\n",
    "    values = [model_parameters[weights],model_parameter[bias]]\n",
    "    d = dict(zip(keys, values))\n",
    "    y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
